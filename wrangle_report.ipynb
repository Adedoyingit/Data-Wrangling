{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The project involved gathering data from twitter, accessing data and cleaning data which is refers to data wrangling.  \n",
    "#### Data Gathering\n",
    "\n",
    "The data gathering involved gathering data from different sources\n",
    "\n",
    "- downloading the dataset by reading in a comma separated value (csv), \n",
    "\n",
    "- get requests library to get data (a tab separated value (tsv) from a url and read it into a dataframe using pandas and\n",
    "\n",
    "- finally obtained a json.txt file from twitter by obtaining twitter developer keys to extract data read into a dataframe, which was reduced to the three needed columns for analysis.\n",
    "\n",
    "#### Assessing Data\n",
    "\n",
    "The issues mentioned above were found by assessing the dataframes both visually and programmatically using some basic pandas functions. The project instructs to remove all retweets from base which I did, before dropping the columns involving retweets. Some of the quality issues detected while accessing the data were;\n",
    "\n",
    "##### Quality issues and how they were fixed\n",
    "1.multiple values in the expanded_url column was noticed when viewed on excel, \n",
    "\n",
    "2.non-descriptive column names in the image dataframe (df_image) noticed both visually and programmatically,\n",
    "\n",
    "3.columns with many null values- dropped columns with many null vlaues, \n",
    "\n",
    "4.incorrect url format- replaced all urls with the most occurred url format ,\n",
    "\n",
    "5.the prediction columns had both capital and lower cases- I converted all to lower cases,\n",
    "\n",
    "6.timestamp had incorrect datatype- fixed this by changing the data type to datetime,\n",
    "\n",
    "7.missing urls-replaced all null values with the most occured url format,\n",
    "\n",
    "8.missing records in the retweet_count and favorite_count columns - I filled null values with the mean of the columns.\n",
    "\n",
    "##### Tidiness issues and how they were fixed\n",
    "\n",
    "1.having four (4) columns representing variable names- used melt to join the columns and dropped duplicates \n",
    "\n",
    "2.repeated tweet_id in the twitter_archived_enhanced dataframe (df_twitter), image-predictions (df_image) and tweet_json.txt (df_tweet_new)- implying we have one dataframe containing all information needed. \n",
    "\n",
    "#### Cleaning Data\n",
    "\n",
    "Cleaning was done in three stages;\n",
    "\n",
    "1.define - defining how to the issue noted in the assessing stage would be cleaned,\n",
    "\n",
    "2.code - converting the definitions into codes that run and\n",
    "\n",
    "3.test - finally testing to ensure the code was implemented correctly. These stages of data cleaning was carried out for each of the issues identified in the assessing stage of the data wrangling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
